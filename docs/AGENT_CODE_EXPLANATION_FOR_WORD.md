# Agent Code Explanation - Word Document Format
## Google Intelligent Group Multi-Agent System

**Document Version:** 1.0  
**Date:** November 2025  
**Author:** Development Team

---

## Executive Summary

This document provides a comprehensive explanation of the agent architecture and code implementation for the Google Intelligent Group Multi-Agent System. The system uses LangChain 1.0 with LangGraph to create a Supervisor-driven multi-agent architecture where a central Supervisor Agent coordinates specialized sub-agents to complete complex tasks.

---

## 1. System Architecture Overview

### 1.1 High-Level Design

The Google Intelligent Group Multi-Agent System implements a **Supervisor-driven Multi-Agent Architecture** with the following components:

**Core Components:**
- **Supervisor Agent**: Central orchestrator using LangGraph
- **Sub-Agents**: Specialized agents for specific tasks
  - GoogleMap Agent (Location searches)
  - Calendar Agent (Event management)
  - Telephone Agent (Phone calls)
  - Research Agent (Information research)
- **LangGraph**: Workflow orchestration as a Directed Acyclic Graph (DAG)
- **LangChain Tools**: Actual functionality implementations

### 1.2 Architecture Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Query  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Supervisor Agent    â”‚
â”‚ (LangGraph)         â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Planning Node       â”‚
â”‚ (Analyze Query)     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Routing Logic       â”‚
â”‚ (Supervisor-driven) â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â–º GoogleMap Agent â”€â”€â–º search_nearby_places tool
       â”œâ”€â”€â–º Calendar Agent â”€â”€â”€â”€â–º add_calendar_event tool
       â”œâ”€â”€â–º Telephone Agent â”€â”€â”€â–º make_phone_call tool
       â””â”€â”€â–º Research Agent â”€â”€â”€â”€â–º research_query tool
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Summarize Node      â”‚
â”‚ (Generate Summary)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Responseâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Supervisor Agent Implementation

### 2.1 File Structure

**Main File:** `backend/agents/supervisor_langgraph.py`

**Key Classes:**
- `AgentState`: TypedDict defining state schema
- `SupervisorAgentLangGraph`: Main supervisor class

### 2.2 AgentState Definition

The `AgentState` is a TypedDict that defines the structure of data flowing through the LangGraph workflow:

```python
class AgentState(TypedDict):
    """State schema for the supervisor agent."""
    messages: Annotated[List, add_messages]      # Conversation history
    agent_outputs: Dict[str, Any]                 # Results from each agent
    execution_order: List[str]                    # Track execution sequence
    query: str                                    # Original user query
    plan: Dict[str, Any]                         # Execution plan
    summary: Optional[str]                        # Final summary
    response: Optional[str]                        # Final response
```

**Explanation of Each Field:**

1. **messages**: Stores the conversation history as LangChain message objects. This allows the LLM to maintain context throughout the workflow.

2. **agent_outputs**: Dictionary where each key is an agent name (e.g., "googleMap", "calendar") and the value is the output from that agent. This accumulates results as agents execute.

3. **execution_order**: List of agent names in the order they were executed. Used by the routing logic to determine which agents have already run.

4. **query**: The original user query string. Passed through the workflow for reference.

5. **plan**: Dictionary containing the execution plan created by the planning node. Includes flags like `use_googlemap`, `use_calendar`, etc.

6. **summary**: The final comprehensive summary generated by the summarize node.

7. **response**: Same as summary, provided for compatibility.

### 2.3 Planning Node (`_plan_node`)

**Purpose:** Analyzes the user query and determines which agents should be used.

**Implementation Details:**

```python
async def _plan_node(self, state: AgentState) -> AgentState:
    query = state.get("query", "")
    
    # Create planning prompt for LLM
    plan_prompt = f"""You are a supervisor agent coordinating multiple specialized agents.
    
    Available agents:
    1. googlemap - Search for nearby places, restaurants, businesses
    2. calendar - Manage calendar events and bookings
    3. telephone - Make phone calls
    4. research - Perform research and answer questions
    
    User query: {query}
    
    Analyze the query and determine which agents should be used.
    Return a JSON object with:
    {{
        "use_googlemap": true/false,
        "use_calendar": true/false,
        "use_telephone": true/false,
        "use_research": true/false,
        "reasoning": "brief explanation"
    }}"""
    
    # Get LLM response
    response = await self.supervisor_llm.ainvoke([HumanMessage(content=plan_prompt)])
    
    # Parse JSON from response
    content = response.content.strip()
    if "```json" in content:
        content = content.split("```json")[1].split("```")[0].strip()
    
    plan = json.loads(content)
    
    # Store plan in state
    state["plan"] = plan
    state["agent_outputs"] = {}
    state["execution_order"] = []
    
    return state
```

**How It Works:**

1. **Receives State**: Gets the current state with the user query
2. **Creates Prompt**: Builds a detailed prompt explaining available agents and asking the LLM to analyze the query
3. **LLM Analysis**: Uses Gemini 2.5 Flash to analyze the query and determine which agents are needed
4. **Parses Response**: Extracts JSON from the LLM response (handles code blocks)
5. **Updates State**: Stores the plan and initializes agent_outputs and execution_order
6. **Returns State**: Returns updated state for the next node

**Example Plan Output:**

For query: "Find Indian restaurant near Taipei 101 and make reservation for tomorrow at 7 PM"

```json
{
    "use_googlemap": true,
    "use_calendar": true,
    "use_telephone": true,
    "use_research": false,
    "reasoning": "Query involves finding restaurant (googlemap), making reservation (calendar and telephone)"
}
```

### 2.4 Supervisor-Driven Routing (`_route_after_plan`)

**Purpose:** Evaluates the current state and intelligently decides which agent to execute next.

**Key Features:**
- **State Evaluation**: Examines plan, execution_order, and agent_outputs
- **Dependency Management**: Ensures agents run in correct order (e.g., GoogleMap before Telephone)
- **Priority System**: Uses priority values to determine execution order
- **Workflow Awareness**: Adjusts routing based on query type (reservation vs. general)

**Implementation:**

```python
def _route_after_plan(self, state: AgentState) -> str:
    """
    Supervisor-driven routing: Evaluates state and decides next agent.
    """
    plan = state.get("plan", {})
    execution_order = state.get("execution_order", [])
    agent_outputs = state.get("agent_outputs", {})
    query = state.get("query", "").lower()
    
    # Supervisor evaluates: What agents are still needed?
    needed_agents = []
    
    # Check GoogleMap: Priority 1 (highest - provides data for others)
    if plan.get("use_googlemap"):
        if "googleMap" not in execution_order:
            needed_agents.append(("googlemap", 1))
    
    # Check Research: Priority 2 (independent)
    if plan.get("use_research"):
        if "research" not in execution_order:
            needed_agents.append(("research", 2))
    
    # Check Calendar and Telephone: Dependencies matter
    is_reservation = any(kw in query for kw in ["reservation", "reserve", "book"])
    has_googlemap_data = "googleMap" in agent_outputs and agent_outputs.get("googleMap", {}).get("success", False)
    
    # For reservations: Calendar before Telephone
    if plan.get("use_calendar"):
        if "calendar" not in execution_order:
            if has_googlemap_data or not plan.get("use_googlemap"):
                priority = 3 if is_reservation else 4
                needed_agents.append(("calendar", priority))
    
    if plan.get("use_telephone"):
        if "telephone" not in execution_order:
            if has_googlemap_data or not plan.get("use_googlemap"):
                priority = 4 if is_reservation else 3
                needed_agents.append(("telephone", priority))
    
    # Supervisor decision: Route to highest priority needed agent
    if needed_agents:
        needed_agents.sort(key=lambda x: x[1])  # Sort by priority
        return needed_agents[0][0]  # Return agent name
    
    # All agents executed - Supervisor routes to summarization
    return "summarize"
```

**Routing Logic Explanation:**

1. **Priority 1 - GoogleMap**: Always runs first if needed because it provides location/phone data for other agents
2. **Priority 2 - Research**: Independent agent, can run anytime
3. **Priority 3/4 - Calendar & Telephone**: 
   - For reservations: Calendar (3) before Telephone (4)
   - For other queries: Telephone (3) before Calendar (4)
4. **Dependency Check**: Telephone and Calendar wait for GoogleMap data if GoogleMap is in the plan
5. **Completion Check**: If no agents are needed, routes to "summarize"

### 2.5 Agent Execution Nodes

Each agent has a dedicated execution node that:
1. Receives state from LangGraph
2. Extracts relevant information
3. Invokes the LangChain agent with tools
4. Processes and formats results
5. Updates state

**Example: GoogleMap Node**

```python
async def _googlemap_node(self, state: AgentState) -> AgentState:
    """Execute GoogleMap agent."""
    try:
        query = state.get("query", "")
        
        # Create enhanced query that encourages tool use
        enhanced_query = f"""You need to search for places using the search_nearby_places tool.

User query: {query}

IMPORTANT: You MUST use the search_nearby_places tool to find the requested places.
Extract:
- The search term (e.g., "Indian restaurant")
- The location (e.g., "Taipei 101")

Then call search_nearby_places with these parameters."""
        
        messages = [HumanMessage(content=enhanced_query)]
        
        # Invoke agent with messages
        result = await self.googlemap_agent.ainvoke({"messages": messages})
        
        # Extract agent output - handle different response formats
        if isinstance(result, dict):
            if "messages" in result:
                last_msg = result["messages"][-1]
                content = last_msg.content if hasattr(last_msg, 'content') else str(last_msg)
            elif "output" in result:
                content = result["output"]
            else:
                content = str(result)
        else:
            content = str(result)
        
        # Format output
        agent_output = {
            "agent": "GoogleMap",
            "success": True,
            "result": content,
            "formatted": content
        }
        
        # Update state
        state["agent_outputs"]["googleMap"] = agent_output
        state["execution_order"].append("googleMap")
        
    except Exception as e:
        # Error handling
        state["agent_outputs"]["googleMap"] = {
            "agent": "GoogleMap",
            "success": False,
            "error": str(e),
            "formatted": f"âŒ GoogleMap Agent Error: {str(e)}"
        }
        state["execution_order"].append("googleMap (failed)")
    
    return state
```

**Key Points:**
- **Enhanced Query**: Creates a prompt that explicitly instructs the agent to use its tool
- **Tool Invocation**: The LangChain agent automatically calls the `search_nearby_places` tool
- **Output Extraction**: Handles different response formats from LangChain
- **State Update**: Stores both raw and formatted outputs
- **Error Handling**: Catches exceptions and stores error information

### 2.6 Summarize Node (`_summarize_node`)

**Purpose:** Generates a comprehensive, natural-language summary from all agent outputs.

**Implementation:**

```python
async def _summarize_node(self, state: AgentState) -> AgentState:
    """Generate final summary."""
    try:
        query = state.get("query", "")
        agent_outputs = state.get("agent_outputs", {})
        
        # Helper function to extract clean text
        def extract_clean_text(value):
            """Extract clean text from various data structures."""
            if isinstance(value, str):
                return value
            if isinstance(value, dict):
                if "text" in value:
                    return value["text"]
                if "content" in value:
                    return extract_clean_text(value["content"])
                if "formatted" in value:
                    return extract_clean_text(value["formatted"])
                return str(value)
            return str(value)
        
        # Extract clean text from all agent outputs
        formatted_outputs = {}
        for agent_name, agent_result in agent_outputs.items():
            if isinstance(agent_result, dict):
                formatted = agent_result.get("formatted") or agent_result.get("result")
                formatted_outputs[agent_name] = extract_clean_text(formatted)
            else:
                formatted_outputs[agent_name] = extract_clean_text(agent_result)
        
        # Build detailed agent summary for prompt
        agent_details = []
        if "googleMap" in formatted_outputs:
            clean_text = formatted_outputs['googleMap']
            if len(clean_text) > 500:
                clean_text = clean_text[:500] + "..."
            agent_details.append(f"ðŸ—ºï¸ GoogleMap Agent: {clean_text}")
        # ... similar for other agents
        
        agent_summary = "\n\n".join(agent_details)
        
        # Create comprehensive summary prompt
        summary_prompt = f"""You are a supervisor agent that coordinates and summarizes results from 4 specialized agents.

USER QUERY: {query}

AGENT RESULTS:
{agent_summary}

TASK: Write a comprehensive, natural-language summary that:
1. Directly addresses the user's query
2. Summarize each agent's contribution
3. Highlight key information
4. Confirm actions taken
5. Be friendly and professional

Write the summary now:"""
        
        # Generate summary using LLM
        response = await self.supervisor_llm.ainvoke([HumanMessage(content=summary_prompt)])
        summary = response.content.strip()
        
        # Store in state
        state["summary"] = summary
        state["response"] = summary
        
    except Exception as e:
        # Fallback summary
        agent_count = len(agent_outputs)
        summary = f"I've successfully processed your request. {agent_count} agent(s) completed their tasks."
        state["summary"] = summary
        state["response"] = summary
    
    return state
```

**Summary Generation Process:**

1. **Extract Clean Text**: Converts complex data structures to readable text
2. **Build Agent Summary**: Creates a formatted summary of each agent's output
3. **Create Prompt**: Builds a detailed prompt asking the LLM to generate a comprehensive summary
4. **LLM Generation**: Uses Gemini to create a natural-language summary
5. **Store Results**: Saves summary in state for streaming to frontend

---

## 3. Sub-Agents Implementation

### 3.1 Agent Factory Pattern

**File:** `backend/agents/agent_factory.py`

**Purpose:** Centralizes the creation of LangChain agents with their respective tools and prompts.

**Why This Pattern?**

1. **Separation of Concerns**: Agent creation logic is isolated from usage
2. **Reusability**: Easy to create multiple instances of the same agent
3. **Maintainability**: Changes to agent configuration are centralized
4. **Testability**: Easy to test agent creation independently

**Implementation Example:**

```python
def create_googlemap_agent():
    """Create GoogleMap Agent with LangChain."""
    api_key = os.getenv("GEMINI_API_KEY")
    model = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        google_api_key=api_key,
        temperature=0.3
    )
    
    system_prompt = """You are a Google Maps search assistant. Your role is to help users find nearby places, restaurants, businesses, and locations.

When searching:
- Extract location information from the query
- Extract search terms
- Use the search_nearby_places tool with appropriate parameters
- Present results clearly with name, address, phone number, and rating

Always provide helpful, accurate location information."""
    
    return create_agent(
        model=model,
        tools=GOOGLEMAP_TOOLS,  # [search_nearby_places]
        system_prompt=system_prompt
    )
```

**Key Components:**

1. **LLM Configuration**: Uses Gemini 2.5 Flash with appropriate temperature
2. **System Prompt**: Defines the agent's role, behavior, and instructions
3. **Tools**: List of LangChain tools the agent can use
4. **Agent Creation**: Uses `create_agent` from LangChain to create the agent

### 3.2 Agent Types

#### GoogleMap Agent
- **Purpose**: Search for locations, restaurants, businesses
- **Tool**: `search_nearby_places`
- **Temperature**: 0.3 (more deterministic)

#### Calendar Agent
- **Purpose**: Manage calendar events and bookings
- **Tools**: `add_calendar_event`, `list_calendar_events`
- **Temperature**: 0.3

#### Telephone Agent
- **Purpose**: Make phone calls via Fonoster
- **Tool**: `make_phone_call`
- **Temperature**: 0.3

#### Research Agent
- **Purpose**: General information and research
- **Tool**: `research_query`
- **Temperature**: 0.7 (more creative)

---

## 4. Tool Definitions

### 4.1 Tool Structure

**File:** `backend/agents/tools.py`

Tools are functions decorated with `@tool` that provide actual functionality to agents. They return JSON strings for consistency.

**Standard Tool Pattern:**

```python
@tool
async def tool_name(param1: str, param2: int) -> str:
    """
    Tool description for the LLM.
    
    Args:
        param1: Description of param1
        param2: Description of param2
    
    Returns:
        JSON string with results
    """
    try:
        # Tool implementation
        result = perform_action(param1, param2)
        return json.dumps(result, ensure_ascii=False)
    except Exception as e:
        return json.dumps({"error": str(e)}, ensure_ascii=False)
```

### 4.2 Available Tools

#### 1. `search_nearby_places`

**Purpose:** Search for places using Google Maps API

**Parameters:**
- `query`: Search term (e.g., "Indian restaurant")
- `location`: Location string (e.g., "Taipei 101")
- `radius`: Search radius in meters (default: 5000)
- `max_results`: Maximum results (default: 5)

**Returns:** JSON string with:
```json
{
    "success": true,
    "results": [
        {
            "name": "Restaurant Name",
            "address": "Full Address",
            "phone_number": "Phone Number",
            "rating": 4.9,
            "location": {"lat": 25.033, "lng": 121.565}
        }
    ]
}
```

**Implementation Flow:**
1. Gets Google Maps API key from environment
2. Builds search query
3. Calls Google Maps Text Search API
4. Gets place details for each result (phone numbers)
5. Formats and returns JSON

#### 2. `add_calendar_event`

**Purpose:** Add an event to the calendar

**Parameters:**
- `title`: Event title
- `date`: Event date (YYYY-MM-DD)
- `time`: Event time (HH:MM format, 24-hour)
- `location`: Event location
- `description`: Event description

**Returns:** JSON string with event details

**Implementation:**
- Uses in-memory calendar storage (can be extended to Google Calendar API)
- Validates date/time format
- Stores event with unique ID
- Returns formatted event details

#### 3. `make_phone_call`

**Purpose:** Make a phone call via Fonoster

**Parameters:**
- `phone_number`: Phone number to call (e.g., "+886912345678")
- `message`: Optional message/context

**Returns:** JSON string with call status

**Implementation:**
- Calls Fonoster server API
- Generates unique call ID
- Returns call initiation status

#### 4. `research_query`

**Purpose:** Perform research using Gemini LLM

**Parameters:**
- `query`: Research question

**Returns:** JSON string with research results

**Implementation:**
- Uses Gemini LLM to answer research questions
- Returns formatted research results

---

## 5. Workflow Execution Example

### Complete Query Processing Flow

**User Query:** "Find Indian restaurant near Taipei 101 and make reservation for tomorrow at 7 PM"

#### Step 1: Initialization
```python
state = {
    "query": "Find Indian restaurant...",
    "messages": [HumanMessage(content="Find Indian restaurant...")],
    "agent_outputs": {},
    "execution_order": [],
    "plan": {},
    "summary": None,
    "response": None
}
```

#### Step 2: Planning Phase
```python
# _plan_node executes
plan = {
    "use_googlemap": True,
    "use_calendar": True,
    "use_telephone": True,
    "use_research": False,
    "reasoning": "Query involves finding restaurant and making reservation"
}

state["plan"] = plan
state["agent_outputs"]["research"] = {"skipped": True, ...}
```

#### Step 3: GoogleMap Agent Execution
```python
# _route_after_plan returns "googlemap"
# _googlemap_node executes

# Agent calls tool
result = search_nearby_places("Indian restaurant", "Taipei 101")
# Returns: List of restaurants with phone numbers

state["agent_outputs"]["googleMap"] = {
    "agent": "GoogleMap",
    "success": True,
    "result": "Restaurant list...",
    "formatted": "Restaurant list..."
}
state["execution_order"].append("googleMap")
```

#### Step 4: Calendar Agent Execution
```python
# _route_after_plan returns "calendar" (has GoogleMap data)
# _calendar_node executes

# Agent calls tool with extracted info
result = add_calendar_event(
    title="Dinner Reservation at Oye Punjabi",
    date="2025-11-19",
    time="19:00",
    location="No. 121è™Ÿ, Yanji St...",
    description="Phone: 02 2775 2065"
)

state["agent_outputs"]["calendar"] = {...}
state["execution_order"].append("calendar")
```

#### Step 5: Telephone Agent Execution
```python
# _route_after_plan returns "telephone" (has GoogleMap data)
# _telephone_node executes

# Agent calls tool with phone from GoogleMap
result = make_phone_call(
    phone_number="+886227752065",
    message="Make reservation for tomorrow at 7 PM"
)

state["agent_outputs"]["telephone"] = {...}
state["execution_order"].append("telephone")
```

#### Step 6: Summarization
```python
# _route_after_plan returns "summarize" (all agents done)
# _summarize_node executes

summary = """Hello! I've coordinated with my specialized agents...
GoogleMap Agent: Found Oye Punjabi Indian Restaurant...
Calendar Agent: Added calendar event...
Telephone Agent: Attempted call...
In summary: Restaurant found, calendar event created..."""

state["summary"] = summary
state["response"] = summary
```

#### Step 7: Response to User
```python
# State is streamed to frontend
# Frontend displays:
# - Supervisor Agent result (summary)
# - Individual agent outputs in sidebar panels
```

---

## 6. Key Design Patterns

### 6.1 Supervisor-Driven Architecture

**Pattern:** The Supervisor evaluates state after each agent completes and makes routing decisions.

**Benefits:**
- Centralized control
- Dynamic adaptation
- State visibility
- Flexible workflows

**Implementation:**
- `_route_after_plan` function evaluates complete state
- Makes intelligent decisions based on:
  - Original plan
  - Current execution status
  - Agent dependencies
  - Workflow context

### 6.2 Tool-Based Agent Design

**Pattern:** Agents use LangChain tools for actual functionality.

**Benefits:**
- Separation of concerns
- Reusability
- Testability
- Clear interfaces

**Implementation:**
- Tools are decorated with `@tool`
- Tools return JSON strings
- Agents automatically use tools based on prompts

### 6.3 State Management with LangGraph

**Pattern:** TypedDict ensures type safety, state flows through graph nodes.

**Benefits:**
- Type safety
- Clear state structure
- Easy debugging
- Predictable flow

**Implementation:**
- `AgentState` TypedDict defines structure
- Each node reads and updates state
- LangGraph manages state flow

### 6.4 Streaming Responses

**Pattern:** Real-time updates to frontend via Server-Sent Events (SSE).

**Benefits:**
- Better user experience
- Real-time feedback
- Task visibility
- Progress tracking

**Implementation:**
- Backend streams state updates
- Frontend receives via SSE
- Updates UI in real-time

---

## 7. Code Examples

### Example 1: Creating and Using an Agent

```python
from agents.agent_factory import create_googlemap_agent
from langchain_core.messages import HumanMessage

# Create agent
agent = create_googlemap_agent()

# Use agent
result = await agent.ainvoke({
    "messages": [HumanMessage(content="Find Indian restaurant near Taipei 101")]
})

# Result contains tool calls and responses
print(result)
```

### Example 2: Complete Supervisor Workflow

```python
from agents.supervisor_langgraph import SupervisorAgentLangGraph

# Initialize supervisor
supervisor = SupervisorAgentLangGraph()

# Process query
query = "Find restaurant and make reservation"

# Stream results
async for chunk in supervisor.stream_query(query):
    print(f"Agent: {chunk.get('execution_order')}")
    print(f"Outputs: {chunk.get('agent_outputs')}")
    if chunk.get('summary'):
        print(f"Summary: {chunk['summary']}")
```

### Example 3: Custom Tool Implementation

```python
from langchain.tools import tool
import json

@tool
async def custom_tool(param: str) -> str:
    """
    Custom tool description.
    
    Args:
        param: Parameter description
    
    Returns:
        JSON string with results
    """
    try:
        # Tool logic
        result = {"success": True, "data": f"Processed {param}"}
        return json.dumps(result, ensure_ascii=False)
    except Exception as e:
        return json.dumps({"success": False, "error": str(e)})
```

---

## 8. Best Practices

### 8.1 Error Handling

**Always handle errors in tools:**
```python
@tool
async def tool_name(param: str) -> str:
    try:
        # Tool logic
        result = perform_action(param)
        return json.dumps(result)
    except Exception as e:
        # Always return JSON, even for errors
        return json.dumps({"success": False, "error": str(e)})
```

### 8.2 Tool Design

**Tools should:**
- Return JSON strings (not objects)
- Handle their own errors
- Be idempotent when possible
- Have clear descriptions for LLM

### 8.3 Agent Prompts

**Prompts should:**
- Clearly define agent role
- Encourage tool use
- Include context from previous agents
- Be specific about expected behavior

### 8.4 State Updates

**Always:**
- Update `execution_order` when agent completes
- Store both raw and formatted outputs
- Maintain state consistency
- Handle failed agents gracefully

---

## 9. Testing

### Testing Individual Agents

```python
# Test GoogleMap agent
from agents.agent_factory import create_googlemap_agent

agent = create_googlemap_agent()
result = await agent.ainvoke({
    "messages": [HumanMessage(content="Find coffee shop near Times Square")]
})
assert "coffee" in str(result).lower()
```

### Testing Supervisor

```python
# Test Supervisor workflow
from agents.supervisor_langgraph import SupervisorAgentLangGraph

supervisor = SupervisorAgentLangGraph()
result = await supervisor.process_query("Find restaurant and make reservation")

assert "googleMap" in result["execution_order"]
assert "calendar" in result["execution_order"]
assert result["summary"] is not None
```

---

## 10. Conclusion

The Google Intelligent Group Multi-Agent System implements a sophisticated Supervisor-driven architecture using LangGraph for workflow orchestration. Each agent is a proper LangChain agent with tools, and the Supervisor coordinates them intelligently based on state evaluation.

**Key Achievements:**
- âœ… Proper multi-agent system (not just LLM task assignment)
- âœ… Supervisor-driven task assignment
- âœ… LangGraph DAG workflow
- âœ… Tool-based agent design
- âœ… Streaming responses
- âœ… Comprehensive error handling

**Future Enhancements:**
- Parallel agent execution where possible
- Retry logic for failed agents
- Dynamic plan adjustment
- Agent result validation
- Enhanced monitoring and logging

---

**Document End**

*This document provides a comprehensive explanation of the agent code architecture. For deployment instructions, see `DEPLOYMENT_GUIDE.md`.*

